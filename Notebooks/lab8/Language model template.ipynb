{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vjQPhRM2yD23",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Language model\n",
    "\n",
    "Language model is a probability distribution over sequences of word.\n",
    "\n",
    "In this lab we will apply laguage model for a classification problem. The task is to implement a filter for spam documents.\n",
    "\n",
    "Read this article\n",
    "https://towardsdatascience.com/learning-nlp-language-models-with-real-data-cdff04c51c25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aU3eVj7NyD25",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataset\n",
    "Download this https://www.kaggle.com/uciml/sms-spam-collection-dataset dataset.\n",
    "Normalize the text and split by sentences using nltk library. Split sentences to the terms. We don't need to do lemmatize words and remove stop words. For simplicity we will lose the punctuation and characters register.\n",
    "Make a lists of sentences for spam and ham messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "WH3j19MKyD27",
    "outputId": "e4790015-cc22-4144-c438-7a9a01d27d9f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      5572 non-null   object\n",
      " 1   v2      5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/spam.csv',delimiter=',',encoding='latin-1')\n",
    "\n",
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\n",
    "df.info()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "21MD-qSbbVsm",
    "outputId": "7e125312-7872-4195-9a39-b22dbcb4c1c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /home/jafar/anaconda3/lib/python3.7/site-packages (1.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "UGSQKOEbbLkL",
    "outputId": "d120c04b-67f0-44af-a9e8-58437baca9dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jafar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jafar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jafar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import unidecode\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5qeMBGKdabaA",
    "outputId": "b5f00c86-44d2-4f70-9845-cdee4f549e63",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello there my master the th'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(text, is_query=False):\n",
    "    text = unidecode.unidecode(text)  # remove accents\n",
    "    text = text.replace('+', ' ')\n",
    "    text = re.sub('(\\w)', lambda m: m.group(0).lower(), text)  # to_lower the entire text\n",
    "    if is_query:\n",
    "        text = re.sub('[^a-z $ *]', \"\", text)  # remove punctuations\n",
    "    else:\n",
    "        text = re.sub('[^a-z ]', \"\", text)\n",
    "    text = re.sub('(\\ +)', \" \", text)  # if we have more than one white space it will become one\n",
    "\n",
    "    return text\n",
    "\n",
    "normalize('Hello there my master the, th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WJ8eKYd3yD3B",
    "outputId": "8e50b37c-9cec-4437-9a78-f52a9e3dd94b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Ham\n",
      "672 4342\n"
     ]
    }
   ],
   "source": [
    "sentences = list(zip(map(normalize, df.v2),df.v1))\n",
    "spam_sentences = list(filter(lambda x: True if x[1] =='spam' else False , sentences))#list of sentences, each sentence represented as a list of terms\n",
    "ham_sentences = list(filter(lambda x: True if x[1] =='ham' else False , sentences))\n",
    "\n",
    "\n",
    "spam_num_sentences = list(map(lambda x:x[0].count('.'),spam_sentences))\n",
    "tokenize = lambda x: x[0].split(' ')\n",
    "spam_sentences = list(map(tokenize,spam_sentences))\n",
    "ham_sentences = list(map(tokenize,ham_sentences))\n",
    "\n",
    "split =  len(spam_sentences) * 9 // 10\n",
    "test_spam = spam_sentences[split:]\n",
    "spam_sentences = spam_sentences[:split]\n",
    "\n",
    "split =  len(ham_sentences) * 9 // 10\n",
    "test_ham = ham_sentences[split:]\n",
    "\n",
    "ham_sentences = ham_sentences[:split]\n",
    "print('Spam', 'Ham')\n",
    "print(len(spam_sentences), len(ham_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CS7qNSY9yD3O",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# clean up\n",
    "un-needed variables deletion to save up ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3hgHwQ4yD3Q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del sentences\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "3p_TBFgVyD3Y",
    "outputId": "e3214e85-7207-4fca-b6b0-9c7c0ab2eea9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [len(spam_sentences), len(ham_sentences)]\n",
    "plt.pie(x, explode=(0,0.1), labels=['Spam', 'Ham'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-0NkDx1yD3i",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Print the average length and average number of sentences in spam message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Lz1LMMZ-yD3j",
    "outputId": "85bc665e-4bef-4e95-f863-9c63518c2380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 21.870535714285715, Average amount of sentences: 0.0\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "avg_length = (functools.reduce(lambda a,b:len(a) + len(b) \\\n",
    "    if isinstance(a,list) else a + len(b),spam_sentences))/len(spam_sentences)\n",
    "\n",
    "avg_sentences = sum(spam_num_sentences)/len(spam_sentences)\n",
    "\n",
    "print(f'Average length: {avg_length}, Average amount of sentences: {avg_sentences}')\n",
    "del avg_sentences\n",
    "del avg_length\n",
    "\n",
    "num_of_words = functools.reduce(lambda a,b:len(a) + len(b) \\\n",
    "    if isinstance(a,list) else a + len(b),spam_sentences+ham_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PueCQupvyD3p"
   },
   "source": [
    "### Unigram model\n",
    "\n",
    "Calculate the number of occurances of each term separately for spam and ham messages.\n",
    "\n",
    "Calculate the total number of terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "h7CruoF_yD3q",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "23NRc7h4yD3r",
    "outputId": "d1268727-e32b-41dd-f63d-45c2c8fbe51d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2182 6974\n"
     ]
    }
   ],
   "source": [
    "spam_words = functools.reduce(lambda a,b:set(a).union(b),spam_sentences)\n",
    "ham_words = functools.reduce(lambda a,b:set(a).union(b),ham_sentences)\n",
    "print(len(spam_words), len(ham_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCrXmsB6yD30"
   },
   "outputs": [],
   "source": [
    "def count_word(sentences, word):\n",
    "    import sys\n",
    "    #print(f'Getting count for word {word} please wait',end='', flush=True)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    return functools.reduce(lambda a,b: a.count(word) + b.count(word) if isinstance(a,list)\\\n",
    "                            else a + b.count(word),sentences)\n",
    "ham_N = len(ham_words)\n",
    "spam_N = len(spam_words)\n",
    "spam_term_c = dict(zip(spam_words,map(lambda a:count_word(spam_sentences, a)\\\n",
    "                                      /spam_N,spam_words)))\n",
    "\n",
    "ham_term_c =dict(zip(ham_words,map(lambda a:count_word(ham_sentences, a)\\\n",
    "                                   /ham_N,ham_words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JdvgBQ1NyD36",
    "outputId": "a0ce1bbb-8481-4756-e3ee-04827a41fe0c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004301691998852882\n"
     ]
    }
   ],
   "source": [
    "print(ham_term_c['sentence'],sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6GHN-YHyD4D",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Print 10 most popular words in spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ouu3r8pWyD4E",
    "outputId": "9b23cf49-ed8e-4d11-ecca-99caf8052ded",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2832263978001833, 'to')\n",
      "(0.15490375802016498, 'a')\n",
      "(0.13932172318973418, 'call')\n",
      "(0.11732355637030248, 'you')\n",
      "(0.10861594867094408, 'aps')\n",
      "(0.10724106324472961, 'your')\n",
      "(0.09074243813015583, '')\n",
      "(0.08845096241979836, 'free')\n",
      "(0.08340971585701192, 'the')\n",
      "(0.08065994500458296, 'now')\n"
     ]
    }
   ],
   "source": [
    "x = list(reversed(sorted(list(zip(map(lambda a:spam_term_c[a],\\\n",
    "                                      spam_words),spam_words)))))\n",
    "print(*x[:10],sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJUiFIQlyD4N",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Bigram model\n",
    "\n",
    "We will use sentence beginning and sentence ending as a special terms. Calculate the number of occuracnies for bigrams. As a key in dictionary you might use words, separated by the space symbol.\n",
    "\n",
    "Also, for a genetative model, epxlained later, for each term we will need a list of next term, found in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m5Kw5jusyD4R",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modify = lambda x: ['<s']+x+['s>']\n",
    "ham_sentences = list(map(modify,ham_sentences))\n",
    "spam_sentences = list(map(modify,spam_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IcJ84ht6yD4Y",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_bigrams(sentences):\n",
    "    big = set([])\n",
    "    for sentence in sentences:\n",
    "        for i in range(0,len(sentence)-1):\n",
    "            big.add(' '.join([sentence[i],sentence[i+1]]))\n",
    "    return big\n",
    "\n",
    "\n",
    "def count_bigs(sentences, index):\n",
    "\n",
    "    for sentence in sentences:\n",
    "        for i in range(0,len(sentence)-1):\n",
    "            index[' '.join([sentence[i],sentence[i+1]])]+=1/len(index.keys())\n",
    "    return index\n",
    "\n",
    "def get_next_spam_word(spam_bigram_c):\n",
    "    res = dict()\n",
    "    x = list(reversed(sorted(list(zip(map(lambda a:spam_bigram_c[a],\\\n",
    "                                      spam_bigram_c.keys()),spam_bigram_c.keys())))))\n",
    "    for _,big in iter(x):\n",
    "        first_word,second_word= iter(big.split(' '))\n",
    "        if first_word in res.keys():\n",
    "            res[first_word].append(second_word)\n",
    "            continue\n",
    "        res[first_word] = [second_word]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gtYphY7cyD4l",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bigrams = add_bigrams(spam_sentences)\n",
    "bigrams = bigrams.union(add_bigrams(ham_sentences))\n",
    "spam_bigram_c = dict(zip(list(bigrams),[0]*len(bigrams)))\n",
    "\n",
    "\n",
    "spam_bigram_c = count_bigs(spam_sentences,spam_bigram_c)\n",
    "\n",
    "spam_next_words = get_next_spam_word(spam_bigram_c)\n",
    "\n",
    "ham_bigram_c = dict(zip(list(bigrams),[0]*len(bigrams)))\n",
    "ham_bigram_c= count_bigs(ham_sentences, ham_bigram_c);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9VsXKW1iyD4r",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Which bigrams are the most popular in spam messages?\n",
    "\n",
    "From which words spam sentence usually begins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "3moU_e8DyD4u",
    "outputId": "a239f6f4-75cc-424f-adca-5371cace7fea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.004183076885442399, ' s>')\n",
      "(0.001565596027300081, 'you have')\n",
      "(0.001565596027300081, 'a aps')\n",
      "(0.0012965092101078796, 'call now')\n",
      "(0.001149734582548497, 'have won')\n",
      "(0.001149734582548497, '<s urgent')\n",
      "(0.0011008097066953694, 'aps prize')\n",
      "(0.0011008097066953694, '<s you')\n",
      "(0.001051884830842242, 'your mobile')\n",
      "(0.0010274223929156781, 'to claim')\n"
     ]
    }
   ],
   "source": [
    "x = list(reversed(sorted(list(zip(map(lambda a:spam_bigram_c[a],\\\n",
    "                                      bigrams),bigrams)))))\n",
    "print(*x[:10],sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4tkQXTCyD41",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Implement a function, which return the conditional probability $P(t_2 | t_1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oV24xSbWyD42",
    "outputId": "bbc6d231-c5b8-402d-9f07-873d51a3de88",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 = I, t2 = am 0.013344259888940535\n",
      "t1 = I, t2 = is 0.006535964027236179\n"
     ]
    }
   ],
   "source": [
    "def conditional_prob(t1, t2, spam=True):\n",
    "    bigram_c = ham_bigram_c\n",
    "    unigram_c = ham_term_c\n",
    "    if spam:\n",
    "        bigram_c = spam_bigram_c\n",
    "        unigram_c = spam_term_c\n",
    "    try:\n",
    "        a = unigram_c[t1]\n",
    "    except:\n",
    "        a = 0\n",
    "    try:\n",
    "        b =  bigram_c[' '.join([t1,t2])]\n",
    "    except:\n",
    "        b = 0\n",
    "    #print(a,b)\n",
    "    return b/a\n",
    "print(\"t1 = I, t2 = am\",conditional_prob('you', 'have'))\n",
    "print(\"t1 = I, t2 = is\",conditional_prob('i', 'am'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fX61TqovyD49",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Genetative model\n",
    "\n",
    "Now is the funny task. Using your language model generate a spam message. Remember you calculated the average number of sentences, average sentence size for spam messages.\n",
    "\n",
    "Print few generated ouptuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I u darlinim cool ill stay whats nannys address it the latest gs still let this txt bundle deals also tel vikky vl givits\n",
      "You our money for driving even move my intention to attend ur hmv to aps tb ok already wat izzit because of hours slave\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_spam_message(spam_next_words,L=23, seed=None):\n",
    "    if not seed:\n",
    "        gen = random.randint(0,len(spam_next_words.keys()))\n",
    "\n",
    "        seed = list(spam_next_words.keys())[gen]\n",
    "    res = seed\n",
    "    for i in range(L):\n",
    "        if not seed in spam_next_words.keys():\n",
    "            gen = random.randint(0,len(spam_next_words.keys()))\n",
    "\n",
    "            seed = list(spam_next_words.keys())[gen]\n",
    "        gen = random.randint(0,len(spam_next_words[seed])-1)\n",
    "        #print(gen, spam_next_words[seed][gen])\n",
    "        res = res +' '+ spam_next_words[seed][gen]\n",
    "        seed = spam_next_words[seed][gen]\n",
    "    return res\n",
    "\n",
    "seeds = ['I', 'You']\n",
    "for seed in seeds:\n",
    "    print(generate_spam_message(spam_next_words,23,seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing\n",
    "\n",
    "The problem is that if the bigram $t_1 t_2$ occuted $0$ times in the corpus, the conditional probability $P(t_2|t_1) = 0$\n",
    "\n",
    "The solution is smoothing. Read this document https://nlp.stanford.edu/~wcmac/papers/20050421-smoothing-tutorial.pdf\n",
    "\n",
    "Your task is to implement one of the advanced (from the document, except additive smoothing) smoothing techniques from it. Be ready to explain it defending the lab.\n",
    "\n",
    "Implement a function, which return the conditional probability $P(t_2 | t_1)$ with a smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4463036352072017e-05"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def turing_good(ngram):\n",
    "  probs = list(map(lambda x: (ngram[x],x) ,ngram.keys()))\n",
    "  probs = list((sorted(probs)))\n",
    "  d = dict()\n",
    "  probabilities = []\n",
    "  keys = []\n",
    "  for i in range(len(probs)):\n",
    "    p = probs[i][0]\n",
    "    if p in d.keys():\n",
    "      d[p]+=1\n",
    "    else:\n",
    "      d[p] = 1\n",
    "   \n",
    "  for i in range(len(probs)-1):\n",
    "    p = probs[i][0]\n",
    "    key = probs[i][1]\n",
    "    nr = d[p]\n",
    "    nr_plus_1 = d[probs[i+1][0]]\n",
    "    N = len(ngram.keys())\n",
    "    p = (p + 1/N/N) * nr / nr_plus_1 #nr_plus_1 / nr\n",
    "    probabilities.append(p)\n",
    "    keys.append(key)\n",
    "  return dict(zip(keys,probabilities))\n",
    "    \n",
    "\n",
    "def smoothing_conditional_prob(t1, t2, spam=True):\n",
    "    bigram_c = ham_bigram_c\n",
    "    unigram_c = ham_term_c\n",
    "    if spam:\n",
    "        bigram_c = spam_bigram_c\n",
    "        unigram_c = spam_term_c\n",
    "    N = len(bigram_c.keys())\n",
    "    z = 1/N\n",
    "    v = 1/(N**2)\n",
    "    try:\n",
    "        a = bigram_c[' '.join([t1,t2])]\n",
    "    except:\n",
    "        a = v\n",
    "    try:\n",
    "        b =  unigram_c[t1]\n",
    "    except:\n",
    "        b = z\n",
    "    return ( a  )/( b)\n",
    "\n",
    "ham_bigram_c = turing_good(ham_bigram_c)\n",
    "spam_term_c = turing_good(spam_term_c)\n",
    "ham_term_c = turing_good(ham_term_c)\n",
    "spam_bigram_c = turing_good(spam_bigram_c)\n",
    "\n",
    "\n",
    "smoothing_conditional_prob('I', 'allah') # // it should be zero nonetheless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Now, implement a bayessian classifier for the sentence. Test one of your generated sentences on it.\n",
    "\n",
    "It should return, which probability is higher\n",
    "\n",
    "$$P(spam|t_1, \\dots , t_k) = \\frac{P(t_1, \\dots , t_k|spam)P(spam)}{P(t_1, \\dots , t_k)} \\sim P(t_1, \\dots , t_k|spam)P(spam)$$ \n",
    "$$\\sim P(t_1 | BEGIN, spam) \\cdot \\sim P(t_2 | t_1, spam) \\cdot \\dots \\cdot \\sim P(END | t_k, spam)$$\n",
    "\n",
    "or the same for ham sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 100.0 %\n",
      "Test accuracy is 93.01075268817203 %\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def classify(sentence):\n",
    "    tokens = sentence.split(' ')\n",
    "    log_spam = math.log(smoothing_conditional_prob('<s', tokens[0],spam=True))\n",
    "    log_ham = math.log(smoothing_conditional_prob('<s', tokens[0],spam=False))\n",
    "\n",
    "    for i in range(len(tokens)-1):\n",
    "        log_spam += math.log(smoothing_conditional_prob(tokens[i],tokens[i+1],spam=True))\n",
    "\n",
    "        log_ham += math.log(smoothing_conditional_prob(tokens[i],tokens[i+1],spam=False))\n",
    "\n",
    "    return  'Spam' if log_spam > log_ham else 'Ham'\n",
    "\n",
    "def evaluate(test_data, labels):\n",
    "  res = 0\n",
    "  for test_sentence, label in iter(zip(test_data,labels)):\n",
    "    if classify(' '.join(test_sentence)) == label:\n",
    "      res+=1\n",
    "  return res/len(test_data) * 100\n",
    "\n",
    "\n",
    "test_data = test_spam + test_ham\n",
    "test_labels = ['Spam'] * len(test_spam) + ['Ham'] * len(test_ham)\n",
    "\n",
    "training_data = spam_sentences + ham_sentences\n",
    "training_labels = ['Spam'] * len(spam_sentences) + ['Ham'] * len(ham_sentences)\n",
    "\n",
    "print(f'Training accuracy is {evaluate(training_data, training_labels)} %')\n",
    "print(f'Test accuracy is {evaluate(test_data, test_labels)} %')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Language model template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
